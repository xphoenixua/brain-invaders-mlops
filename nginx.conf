worker_processes 1; # number of CPU cores per instance

events {
    worker_connections 1024; # number of connections per worker (CPU core), it's like number of requests that can be handled concurrently
}

http {
    resolver 127.0.0.11 valid=5s;

    upstream champion_serving_app {
        server model-serving-champion:8000;
    }

    upstream challenger_serving_app {
        server model-serving-challenger:8000;
    }

    server {
        listen 80;

        location /predict-champion/ {
            proxy_pass http://champion_serving_app/predict/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_buffering off;
        }

        location /predict-challenger/ {
            proxy_pass http://challenger_serving_app/predict/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_buffering off;
        }

        location /health-champion {
            proxy_pass http://champion_serving_app/health;
        }

        location /health-challenger {
            proxy_pass http://challenger_serving_app/health;
        }

        location /nginx_health {
            access_log off;
            return 200 "nginx is healthy";
            add_header Content-Type text/plain;
        }
    }
}