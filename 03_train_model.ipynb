{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a90ab90-61aa-477b-a458-2eea9aa485c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "# --- configuration ---\n",
    "# define widgets for job parameters, with defaults for interactive runs\n",
    "dbutils.widgets.text(\"processed_data_path\", \"/dbfs/FileStore/tables/p300_files/processed-features/\", \"DBFS path to processed features\")\n",
    "dbutils.widgets.text(\"experiment_name\", f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/P300_BCI_Training\", \"MLflow Experiment Name\")\n",
    "dbutils.widgets.text(\"registered_model_name\", \"P300-Classifier\", \"MLflow Registered Model Name\")\n",
    "\n",
    "# get values from widgets\n",
    "processed_data_root_path = dbutils.widgets.get(\"processed_data_path\")\n",
    "mlflow_experiment_name = dbutils.widgets.get(\"experiment_name\")\n",
    "mlflow_registered_model_name = dbutils.widgets.get(\"registered_model_name\")\n",
    "\n",
    "# set the MLflow experiment\n",
    "mlflow_registry_uri = \"databricks\"\n",
    "mlflow.set_registry_uri(mlflow_registry_uri)\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n",
    "display(f\"MLflow experiment set to: {mlflow_experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d5870c-ebc4-4e9d-a410-592b717293b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# configuration for model and training\n",
    "MODEL_CONFIG = {\n",
    "    \"type\": \"LDA\",\n",
    "    \"lda_solver\": \"lsqr\",\n",
    "    \"lda_shrinkage\": \"auto\",\n",
    "    \"ridge_alphas\": np.logspace(-3, 3, 7)\n",
    "}\n",
    "TARGET_CLASS_LABEL_CODE = 2\n",
    "INTERNAL_VAL_SPLIT_RATIO = 0.8\n",
    "\n",
    "# helper function for evaluation\n",
    "def evaluate_model_sklearn(model, x_test, y_test, scaler_instance=None):\n",
    "    x_test_scaled = scaler_instance.transform(x_test) if scaler_instance else x_test\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "    \n",
    "    y_test_binary = np.where(y_test == TARGET_CLASS_LABEL_CODE, 1, 0)\n",
    "    y_pred_binary = np.where(y_pred == TARGET_CLASS_LABEL_CODE, 1, 0)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "    kappa = cohen_kappa_score(y_test_binary, y_pred_binary)\n",
    "    auc = None\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        target_class_idx = list(model.classes_).index(TARGET_CLASS_LABEL_CODE)\n",
    "        y_pred_proba_target = model.predict_proba(x_test_scaled)[:, target_class_idx]\n",
    "        if len(np.unique(y_test_binary)) > 1:\n",
    "            auc = roc_auc_score(y_test_binary, y_pred_proba_target)\n",
    "            \n",
    "    return {\"accuracy\": accuracy, \"kappa\": kappa, \"auc\": auc}\n",
    "\n",
    "\n",
    "# package model and scaler together\n",
    "class SklearnModelWithScaler(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model, scaler):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        scaled_input = self.scaler.transform(model_input.values)\n",
    "        predictions = self.model.predict(scaled_input)\n",
    "        \n",
    "        # prepare a dictionary for each row of the output\n",
    "        results = []\n",
    "        probabilities = self.model.predict_proba(scaled_input)\n",
    "        target_class_idx = list(self.model.classes_).index(TARGET_CLASS_LABEL_CODE)\n",
    "        \n",
    "        for i, pred in enumerate(predictions):\n",
    "            results.append({\n",
    "                \"predicted_label_code\": int(pred),\n",
    "                \"predicted_class_name\": \"Target\" if int(pred) == TARGET_CLASS_LABEL_CODE else \"NonTarget\",\n",
    "                \"probability_target\": float(probabilities[i, target_class_idx])\n",
    "            })\n",
    "        \n",
    "        # return a pandas series of dictionary objects for easy parsing\n",
    "        return pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0614f3cd-abcb-4e31-95ca-13b6f8e92bb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# data loading logic from DBFS\n",
    "all_x, all_y = [], []\n",
    "all_subject_folders = [os.path.join(processed_data_root_path, d) for d in os.listdir(processed_data_root_path)]\n",
    "display(f\"found {len(all_subject_folders)} processed subject folders.\")\n",
    "\n",
    "for subject_folder_path in all_subject_folders:\n",
    "    features_path = os.path.join(subject_folder_path, \"features.parquet\")\n",
    "    labels_path = os.path.join(subject_folder_path, \"labels.parquet\")\n",
    "    \n",
    "    if os.path.exists(features_path) and os.path.exists(labels_path):\n",
    "        x_df = pd.read_parquet(features_path)\n",
    "        y_df = pd.read_parquet(labels_path)\n",
    "        all_x.append(x_df.values)\n",
    "        all_y.append(y_df['label'].values)\n",
    "    else:\n",
    "        display(f\"  warning: missing features or labels for {subject_folder_path}. skipping.\")\n",
    "\n",
    "x_combined = np.vstack(all_x)\n",
    "y_combined = np.concatenate(all_y)\n",
    "display(f\"successfully loaded and combined data. features shape: {x_combined.shape}, labels shape: {y_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4929fe7-7b10-4e4b-a4b6-7e4a4d54d824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "    \n",
    "# MLflow training run\n",
    "with mlflow.start_run(run_name=\"LDA_Training_Run\") as run:\n",
    "    display(f\"starting MLflow run with ID: {run.info.run_id}\")\n",
    "    \n",
    "    # log parameters\n",
    "    mlflow.log_param(\"model_type\", MODEL_CONFIG['type'])\n",
    "    if MODEL_CONFIG['type'] == \"LDA\":\n",
    "        mlflow.log_param(\"lda_solver\", MODEL_CONFIG.get(\"lda_solver\"))\n",
    "        mlflow.log_param(\"lda_shrinkage\", MODEL_CONFIG.get(\"lda_shrinkage\"))\n",
    "    \n",
    "    mlflow.log_param(\"internal_val_split_ratio\", INTERNAL_VAL_SPLIT_RATIO)\n",
    "    mlflow.log_param(\"num_subjects_trained_on\", len(all_subject_folders))\n",
    "\n",
    "\n",
    "    # split data\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_combined, y_combined, \n",
    "        test_size=(1.0 - INTERNAL_VAL_SPLIT_RATIO),\n",
    "        stratify=y_combined, \n",
    "        random_state=42\n",
    "    )\n",
    "    mlflow.log_param(\"training_set_size\", x_train.shape[0])\n",
    "    mlflow.log_param(\"validation_set_size\", x_val.shape[0])\n",
    "\n",
    "\n",
    "    # train model and scaler\n",
    "    scaler = StandardScaler()\n",
    "    model = LinearDiscriminantAnalysis(solver=MODEL_CONFIG['lda_solver'], shrinkage=MODEL_CONFIG['lda_shrinkage'])\n",
    "    \n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    \n",
    "\n",
    "    # evaluate and log metrics\n",
    "    metrics = evaluate_model_sklearn(model, x_val, y_val, scaler_instance=scaler)\n",
    "    metrics_to_log = {f\"validation_{k}\": v for k, v in metrics.items() if v is not None}\n",
    "    mlflow.log_metrics(metrics_to_log)\n",
    "    display(\"model metrics logged:\")\n",
    "    display(metrics_to_log)\n",
    "    \n",
    "    # log training subject names\n",
    "    training_subject_names = [os.path.basename(p) for p in all_subject_folders]\n",
    "    mlflow.log_param(\"training_subject_names\", \", \".join(training_subject_names))\n",
    "    training_subjects_payload = {\"training_subjects\": training_subject_names}\n",
    "    mlflow.log_dict(training_subjects_payload, \"training_subjects.json\")\n",
    "\n",
    "    # log and register the model\n",
    "    input_example = pd.DataFrame(x_train[:5,:], columns=[f\"feature_{i}\" for i in range(x_train.shape[1])])\n",
    "    pyfunc_artifact_path = \"p300-pyfunc-model\"\n",
    "    pyfunc_model_with_scaler = SklearnModelWithScaler(model=model, scaler=scaler)\n",
    "    \n",
    "    registered_model_info = mlflow.pyfunc.log_model(\n",
    "        name=pyfunc_artifact_path,\n",
    "        python_model=pyfunc_model_with_scaler,\n",
    "        input_example=input_example,\n",
    "        )\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/{pyfunc_artifact_path}\"\n",
    "    \n",
    "    print(f\"registering model from URI: {model_uri}\")\n",
    "    registered_model_info = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=mlflow_registered_model_name\n",
    "    )\n",
    "    new_model_version = registered_model_info.version\n",
    "\n",
    "\n",
    "    # this is the legacy method for updating the model stage\n",
    "    # aliases don't work with Workspace Registry (DBFS based approach)\n",
    "    client = MlflowClient()\n",
    "    client.transition_model_version_stage(\n",
    "        name=mlflow_registered_model_name,\n",
    "        version=new_model_version,\n",
    "        stage=\"Staging\",\n",
    "        archive_existing_versions=True # this will move any other version currently in 'Staging' to 'Archived'\n",
    "    )\n",
    "\n",
    "\n",
    "    display(f\"model successfully packaged with scaler and registered as '{mlflow_registered_model_name} version {new_model_version}' in 'Staging'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_train_model",
   "widgets": {
    "experiment_name": {
     "currentValue": "/Users/kalapun.pn@ucu.edu.ua/P300_BCI_Training",
     "nuid": "90ea101d-c3d9-4e69-aa9f-0bd346a0135e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Users/kalapun.pn@ucu.edu.ua/P300_BCI_Training",
      "label": "MLflow Experiment Name",
      "name": "experiment_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Users/kalapun.pn@ucu.edu.ua/P300_BCI_Training",
      "label": "MLflow Experiment Name",
      "name": "experiment_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "processed_data_path": {
     "currentValue": "/dbfs/FileStore/tables/p300_files/processed-features/",
     "nuid": "d38a86bb-e87c-44de-a769-a5196e51eeb3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/dbfs/FileStore/tables/p300_files/processed-features/",
      "label": "DBFS path to processed features",
      "name": "processed_data_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/dbfs/FileStore/tables/p300_files/processed-features/",
      "label": "DBFS path to processed features",
      "name": "processed_data_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "registered_model_name": {
     "currentValue": "P300-Classifier",
     "nuid": "606ad722-ac9b-440d-90fc-334a21459ff9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "P300-Classifier",
      "label": "MLflow Registered Model Name",
      "name": "registered_model_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "P300-Classifier",
      "label": "MLflow Registered Model Name",
      "name": "registered_model_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
